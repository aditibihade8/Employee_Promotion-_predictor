{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_3.csv\")\n",
    "df.drop(columns = [\"employee_id\",\"Unnamed: 0\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as ltb\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.metrics import f1_score \n",
    "\n",
    "#X_train,X_test,y_train,y_test = tts(df.drop('is_promoted', axis = 1),df['is_promoted'],test_size = 0.3,random_state = 1)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "PF = PolynomialFeatures(2);\n",
    "data_p = PF.fit_transform(df.drop('is_promoted',axis = 1))\n",
    "Xp_train,Xp_test,y_train,y_test = tts(data_p,df['is_promoted'],test_size = 0.3,random_state = 1)\n",
    "\n",
    "#Feature Scaling\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "#Xp_train = sc.fit_transform(Xp_train)\n",
    "#Xp_test = sc.transform(Xp_test)\n",
    "\n",
    "model = ltb.LGBMClassifier()\n",
    "model.fit(Xp_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5566739606126915\n",
      "0.525554981930821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "\n",
    "pred1 = model.predict(Xp_train)\n",
    "pred = model.predict(Xp_test)\n",
    "print(f1_score(pred1,y_train))\n",
    "print(f1_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv(\"Test_2.csv\")\n",
    "df1 = dfr[\"employee_id\"]\n",
    "#dfr.drop(columns = [\"employee_id\"],inplace = True)\n",
    "dfr.drop(columns = [\"employee_id\",\"Unnamed: 0\"],inplace = True)\n",
    "#dfr = dfr.drop(columns = [\"other\", \"referred\" , \"sourcing\"])\n",
    "data_p1 = PF.fit_transform(dfr)\n",
    "t=model.predict(data_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.DataFrame(t)\n",
    "dfr1 = pd.concat((df1,T),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr1.to_csv(\"lgbm_fsc_poly3_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.metrics import f1_score \n",
    "\n",
    "#X_train,X_test,y_train,y_test = tts(df.drop('is_promoted', axis = 1),df['is_promoted'],test_size = 0.3,random_state = 1)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "PF = PolynomialFeatures(2);\n",
    "data_p = PF.fit_transform(df.drop('is_promoted',axis = 1))\n",
    "Xp_train,Xp_test,y_train,y_test = tts(data_p,df['is_promoted'],test_size = 0.3,random_state = 1)\n",
    "\n",
    "\n",
    "#Feature Scaling\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "#Xp_train = sc.fit_transform(Xp_train)\n",
    "#Xp_test = sc.transform(Xp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def run_lgb(X_train, X_test, y_train, y_test, test_df):\n",
    "    d_train = lgb.Dataset(Xp_train, label=y_train)\n",
    "    params = {\n",
    "       \"objective\" : \"binary\",\n",
    "       \"n_estimators\":10000,\n",
    "       \"reg_alpha\" : 0.1,\n",
    "       \"reg_lambda\":0.1,\n",
    "       \"n_jobs\":-1,\n",
    "       \"colsample_bytree\":.8,\n",
    "       \"min_child_weight\":8,\n",
    "       \"subsample\":0.8715623,\n",
    "       \"min_data_in_leaf\":100,\n",
    "       \"nthread\":4,\n",
    "       \"metric\" : \"f1\",\n",
    "       \"num_leaves\" : 600,\n",
    "       \"learning_rate\" : 0.01,\n",
    "       \"verbosity\" : -1,\n",
    "       \"seed\": 120,\n",
    "       \"max_bin\":60,\n",
    "       'max_depth':15,\n",
    "       'min_gain_to_split':.0222415,\n",
    "       'scale_pos_weight':2\n",
    "        }\n",
    "#clf = lgb.train(params, d_train, 100)\n",
    "\n",
    "    lgtrain = lgb.Dataset(Xp_train, label=y_train)\n",
    "    lgval = lgb.Dataset(Xp_test, label=y_test)\n",
    "    evals_result = {}\n",
    "    clf = lgb.train(params, lgtrain, 10000, \n",
    "                      valid_sets=[lgtrain, lgval], \n",
    "                      early_stopping_rounds=100, \n",
    "                      verbose_eval=100, \n",
    "                      evals_result=evals_result,feval=lgb_f1_score)\n",
    "    pred_test_y = clf.predict(test_df, num_iteration=clf.best_iteration)\n",
    "    return pred_test_y, clf, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shashank\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Shashank\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's f1: 0.440718\tvalid_1's f1: 0.446797\n",
      "[200]\ttraining's f1: 0.515044\tvalid_1's f1: 0.508598\n",
      "[300]\ttraining's f1: 0.545377\tvalid_1's f1: 0.51659\n",
      "[400]\ttraining's f1: 0.562053\tvalid_1's f1: 0.530735\n",
      "[500]\ttraining's f1: 0.569583\tvalid_1's f1: 0.530348\n",
      "[600]\ttraining's f1: 0.578283\tvalid_1's f1: 0.531558\n",
      "[700]\ttraining's f1: 0.590788\tvalid_1's f1: 0.536992\n",
      "[800]\ttraining's f1: 0.600163\tvalid_1's f1: 0.533333\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's f1: 0.591532\tvalid_1's f1: 0.537255\n",
      "LightGBM Training Completed...\n"
     ]
    }
   ],
   "source": [
    "pred_test, clf, evals_result = run_lgb(Xp_train, Xp_test, y_train, y_test, data_p1)\n",
    "print(\"LightGBM Training Completed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv(\"Test_2.csv\")\n",
    "df1 = dfr[\"employee_id\"]\n",
    "#dfr.drop(columns = [\"employee_id\"],inplace = True)\n",
    "dfr.drop(columns = [\"employee_id\",\"Unnamed: 0\"],inplace = True)\n",
    "#dfr = dfr.drop(columns = [\"other\", \"referred\" , \"sourcing\"])\n",
    "data_p1 = PF.fit_transform(dfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23490"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,23490):\n",
    "    if pred_test[i]>=.44:       # setting threshold to .5\n",
    "       pred_test[i]=1\n",
    "    else:  \n",
    "       pred_test[i]=0\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.DataFrame(pred_test)\n",
    "dfr1 = pd.concat((df1,T),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr1.to_csv(\"lgbm_paramtune_featurescl_0.4thresh_poly2_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
